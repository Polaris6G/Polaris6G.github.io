<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"polaris6g.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Hadoop介绍 Hadoop部署  大数据基础平台安装实操目标">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop实操概述">
<meta property="og:url" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/index.html">
<meta property="og:site_name" content="Polaris6G&#39;s blog">
<meta property="og:description" content="Hadoop介绍 Hadoop部署  大数据基础平台安装实操目标">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714151807160.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714152057735.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714152500028.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714152950749.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714153125362.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714153325977.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714153630885.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220715193833455.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721123948884.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721125506134.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721125820845.png">
<meta property="og:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721125417043.png">
<meta property="article:published_time" content="2022-07-15T11:40:42.000Z">
<meta property="article:modified_time" content="2022-07-22T12:53:10.166Z">
<meta property="article:author" content="Zhao.W.L">
<meta property="article:tag" content="思特奇培训课程">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714151807160.png">

<link rel="canonical" href="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Hadoop实操概述 | Polaris6G's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Polaris6G's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay humble,stay hungry.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhao.W.L">
      <meta itemprop="description" content="This is a blog in order to record my learning and growth.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Polaris6G's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop实操概述
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-15 19:40:42" itemprop="dateCreated datePublished" datetime="2022-07-15T19:40:42+08:00">2022-07-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-07-22 20:53:10" itemprop="dateModified" datetime="2022-07-22T20:53:10+08:00">2022-07-22</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <ul>
<li>Hadoop介绍</li>
<li><p>Hadoop部署</p>
</li>
<li><p>大数据基础平台安装实操目标</p>
</li>
</ul>
<span id="more"></span>
<h1 id="Hadoop介绍"><a href="#Hadoop介绍" class="headerlink" title="Hadoop介绍"></a>Hadoop介绍</h1><p>分布式存储组件：HDFS</p>
<ul>
<li>分布式存储系统</li>
<li>提供了高可靠性、高扩展性、高吞吐率和高容错率的数据存储服务</li>
</ul>
<p>资源管理系统：YARN</p>
<ul>
<li>负责集群资源的统一管理和调度</li>
</ul>
<p>分布式计算框架：MapReduce</p>
<ul>
<li>分布式计算框架</li>
<li>具有易于编程、高容错和高扩展等优点</li>
</ul>
<p><strong>版本技术衍进</strong></p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714151807160.png" class title="image-20220714151807160">
<h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p><strong>结构</strong></p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714152057735.png" class title="image-20220714152057735">
<p><strong>特点</strong></p>
<ul>
<li><p>扩展性：横向无限扩展</p>
</li>
<li><p>高容错性：备份机制</p>
</li>
<li><p>适合PB级以上海量数据的存储</p>
</li>
</ul>
<p><strong>节点</strong></p>
<ul>
<li><p>Namenode</p>
</li>
<li><p>Datanode</p>
</li>
</ul>
<p><strong>基本原理</strong></p>
<ul>
<li>将文件切分成等大数据块，存储到多台机器上</li>
<li>将数据切分、容错、负载均衡等功能透明化</li>
<li>可将HDFS看成一个容量巨大、具有高容错性的磁盘</li>
</ul>
<h3 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h3><img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714152500028.png" class title="image-20220714152500028">
<ul>
<li>Hadoop 2.0新增系统</li>
<li>负责集群的资源管理和调度</li>
<li>使得多种计算框架可以运行在一个集群中</li>
</ul>
<p><strong>节点</strong></p>
<ul>
<li><p>Resource Manager</p>
</li>
<li><p>Node Manager</p>
</li>
</ul>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p><strong>两个阶段</strong></p>
<ul>
<li><p>map</p>
</li>
<li><p>reduce</p>
</li>
</ul>
<p><strong>特点</strong></p>
<ul>
<li>良好扩展性</li>
<li>高容错性</li>
<li>适合PB级以上海量的离线处理</li>
</ul>
<p><strong>计算流程</strong></p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714152950749.png" class title="image-20220714152950749">
<h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><p>进程：QuorumPeerMain</p>
<h3 id="QJM"><a href="#QJM" class="headerlink" title="QJM"></a>QJM</h3><p>进程：JournalNode</p>
<p><strong>汇总</strong></p>
<p>HDFS： Namenode 、Datanode、JournalNode（主从Namenode数据同步）、zkfc(Namenode故障转移)</p>
<p>YARN： Resource Manager、Node Manager</p>
<p>MapReduce： map、reduce</p>
<p>Zookeeper： QuorumPeerMain</p>
<h1 id="Hadoop部署"><a href="#Hadoop部署" class="headerlink" title="Hadoop部署"></a>Hadoop部署</h1><img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714153125362.png" class title="image-20220714153125362">
<p><strong>部署模式</strong></p>
<ul>
<li>本地模式</li>
<li><p>伪分布式模式</p>
</li>
<li><p>完全分布式模式</p>
</li>
</ul>
<h3 id="集群部署设置"><a href="#集群部署设置" class="headerlink" title="集群部署设置"></a>集群部署设置</h3><img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714153325977.png" class title="image-20220714153325977">
<h1 id="大数据基础平台安装实操目标"><a href="#大数据基础平台安装实操目标" class="headerlink" title="大数据基础平台安装实操目标"></a>大数据基础平台安装实操目标</h1><img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220714153630885.png" class title="image-20220714153630885">
<h3 id="mysql安装使用"><a href="#mysql安装使用" class="headerlink" title="mysql安装使用"></a>mysql安装使用</h3><p>1、创建安装用户及目录规划</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">useradd -d /iddbs iddbs</span><br><span class="line">cat /etc/passwd</span><br><span class="line">cat /etc/group</span><br><span class="line">passwd iddbs</span><br><span class="line">mkdir /dbdata</span><br><span class="line">chown -R iddbs:iddbs /dbdata</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>目录名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>/iddbs</td>
<td>MySQL程序目录</td>
</tr>
<tr>
<td>/iddbs/mysql-5.7.36</td>
<td>MySQL执行程序目录</td>
</tr>
<tr>
<td>/iddbs/software</td>
<td>常用软件存放目录</td>
</tr>
<tr>
<td>/iddbs/scripts</td>
<td>常用脚本存放目录</td>
</tr>
<tr>
<td>/dbdata</td>
<td>MySQL总数据目录</td>
</tr>
<tr>
<td>/dbdata/$port</td>
<td>MySQL实例目录</td>
</tr>
<tr>
<td>/dbdata/$port/${port}.cfg</td>
<td>MySQL实例配置文件</td>
</tr>
<tr>
<td>/dbdata/$port/data</td>
<td>MySQL实例数据存放目录</td>
</tr>
<tr>
<td>/dbdata/$port/binlog</td>
<td>MySQL实例Binlog存放目录</td>
</tr>
<tr>
<td>/dbdata/$port/logs</td>
<td>MySQL error/slow/general存放目录</td>
</tr>
<tr>
<td>/dbdata/$port/tmp</td>
<td>MySQL实例临时目录</td>
</tr>
<tr>
<td>/dbdata/backup</td>
<td>MySQL备份目录</td>
</tr>
</tbody>
</table>
</div>
<p>2、上传并解压安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf mysql-5.7.36-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv mysql-5.7.36-linux-glibc2.12-x86_64 /iddbs/mysql-5.7.36</span><br></pre></td></tr></table></figure>
<p>3、准备my.cnf文件</p>
<p>4、初始化</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/iddbs/mysql-5.7.36/bin/mysqld --defaults-file=/dbdata/3306/3306.cfg --user=iddbs --initialize-insecure</span><br></pre></td></tr></table></figure>
<p>5、启动MySQL服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/iddbs/mysql-5.7.36/bin/mysqld_safe --defaults-file=/dbdata/3306/3306.cfg &amp;</span><br></pre></td></tr></table></figure>
<p>6、登录MySQL数据库</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/iddbs/mysql-5.7.36/bin/mysql  -uroot -p  -S /dbdata/3306/mysql.sock</span><br></pre></td></tr></table></figure>
<p>7、创建数据库owndb </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database owndb;</span><br></pre></td></tr></table></figure>
<p>8、给owndb远程登录权限</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;N@2510las&#39; with grant option;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<p>9、给owndb创建用户owndbuser</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create user &#39;owndbuser&#39;@&#39;%&#39; identified by &#39;Polais6G&#39;;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<p>10、给owndb用户owndbuser授权</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grant all on owndb.* to &#39;owndbuser&#39;@&#39;%&#39;;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<h3 id="大数据基础平面部署准备"><a href="#大数据基础平面部署准备" class="headerlink" title="大数据基础平面部署准备"></a>大数据基础平面部署准备</h3><div class="table-container">
<table>
<thead>
<tr>
<th>IP</th>
<th>主机名</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.80.132</td>
<td>e3base01</td>
<td>QuorumPeerMain、Namenode、datanode、zkfc、journalnode、resourcemanager、nodemanager</td>
</tr>
<tr>
<td>192.168.80.133</td>
<td>e3base02</td>
<td>QuorumPeerMain、Namenode、datanode、zkfc、journalnode、resourcemanager、nodemanager</td>
</tr>
<tr>
<td>192.168.80.134</td>
<td>e3base03</td>
<td>QuorumPeerMain、datanode、journalnode、nodemanager</td>
</tr>
<tr>
<td>192.168.80.131</td>
<td>mysql01</td>
<td>mysql</td>
</tr>
</tbody>
</table>
</div>
<p>1、找一台主机克隆，克隆后配置好对应环境。</p>
<p>2、配置IP</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>
<p>3、关闭防火墙</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld #永久关闭</span><br><span class="line"></span><br><span class="line">systemctl stop firewalld #暂时关闭 </span><br></pre></td></tr></table></figure>
<p>4、修改主机名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname e3base01</span><br></pre></td></tr></table></figure>
<p>5、配置/etc/hosts</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">192.168.80.141 e3base01</span><br><span class="line"></span><br><span class="line">192.168.80.142 e3base02</span><br><span class="line"></span><br><span class="line">192.168.80.143 e3base03</span><br></pre></td></tr></table></figure>
<p>6、创建e3base 用户，并创建对应的用数据目录/chunk1 之后授权给e3base:e3base</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">useradd -d /e3base e3base</span><br><span class="line"></span><br><span class="line">mkdir /chunk1</span><br><span class="line"></span><br><span class="line">chown -R e3base:e3base  /chunk1</span><br><span class="line"></span><br><span class="line">passwd e3base</span><br></pre></td></tr></table></figure>
<p>7、修改ulimit 的值</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ulimit -u 65536 /ulimit -n 1048576 /ulimit -s 262144 /ulimit -c 65536</span><br></pre></td></tr></table></figure>
<p>8、创建/var/run/hadoop-hdfs/ 授权给 e3base:e3base  修改权限为755</p>
<p>ps：只要重启虚拟机，这个路径就会消失，所以每次重新创建</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir /var/run/hadoop-hdfs/</span><br><span class="line"></span><br><span class="line">chown -R e3base:e3base  /var/run/hadoop-hdfs/</span><br><span class="line"></span><br><span class="line">chmod -R 755 /var/run/hadoop-hdfs/ </span><br></pre></td></tr></table></figure>
<p>9、安装JDK</p>
<p>10、配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim .bash_profile</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">export PATH</span><br><span class="line"></span><br><span class="line">export IN_HOME=/e3base</span><br><span class="line"></span><br><span class="line">export E3_INFO_HOME=/e3base/e3-info</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\##jdk</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/e3base/jdk</span><br><span class="line"></span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\##zookeeper</span><br><span class="line"></span><br><span class="line">export ZOO_HOME=$IN_HOME/zookeeper</span><br><span class="line"></span><br><span class="line">export PATH=$ZOO_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">\#hadoop</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=$IN_HOME/hadoop</span><br><span class="line"></span><br><span class="line">export PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\#hive</span><br><span class="line"></span><br><span class="line">export HIVE_HOME=$IN_HOME/hive</span><br><span class="line"></span><br><span class="line">export PATH=$HIVE_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source .bash_profile</span><br></pre></td></tr></table></figure>
<p>测试:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -verison</span><br></pre></td></tr></table></figure>
<p>11、克隆主机</p>
<p>12、修改主机的IP</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>
<p>13、修改主机名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname e3base02</span><br><span class="line"></span><br><span class="line">hostnamectl set-hostname e3base03</span><br></pre></td></tr></table></figure>
<p>14、配置ssh免密</p>
<p>root模式下修改：</p>
<p>SELINUX=disable</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;selinux&#x2F;config</span><br></pre></td></tr></table></figure>
<p>三台主机执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa	#生成私钥和密钥</span><br><span class="line"></span><br><span class="line">ssh-copy-id e3base01	#发放密匙</span><br></pre></td></tr></table></figure>
<p>在e3base01 主机执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp authorized_keys e3base02:/e3base/.ssh/</span><br><span class="line">scp authorized_keys e3base03:/e3base/.ssh/</span><br></pre></td></tr></table></figure>
<h3 id="zookeeper部署"><a href="#zookeeper部署" class="headerlink" title="zookeeper部署"></a>zookeeper部署</h3><p>1、安装解压zookeeper-3.4.5-cdh5.14.0-e3base3.0.0.tar.gz到/e3base/cdh5140</p>
<p>2、创建软连接（快捷方式）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /e3base/cdh5140/zookeeper-3.4.5-cdh5.14.0-e3base3.0.0 /e3base/zookeeper</span><br></pre></td></tr></table></figure>
<p>3、添加zookeeper相关的环境变量。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi .bash_profile</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export IN_HOME=/e3base/</span><br><span class="line"></span><br><span class="line">export ZOO_HOME=$IN_HOME/zookeeper</span><br><span class="line"></span><br><span class="line">export PATH=$ZOO_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>使其生效：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source .bash_profile</span><br></pre></td></tr></table></figure>
<p>4、创建$E3_INFO_HOME/zookeeper/data目录。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $E3_INFO_HOME/zookeeper/data</span><br></pre></td></tr></table></figure>
<p>5、修改/e3base/zookeeper/conf/zookeeper-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/e3base/jdk</span><br><span class="line"></span><br><span class="line">export ZOO_LOG_DIR=/e3base/e3-info/zookeeper/logs</span><br></pre></td></tr></table></figure>
<p>6、修改/e3base/zookeeper/conf/zoo.cfg配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/e3base/e3-info/zookeeper/data</span><br><span class="line"></span><br><span class="line">clientPort=11001</span><br><span class="line"></span><br><span class="line">server.1=e3base01:11002:11003</span><br><span class="line"></span><br><span class="line">server.2=e3base02:11002:11003</span><br><span class="line"></span><br><span class="line">server.3=e3base03:11002:11003</span><br><span class="line"></span><br><span class="line">maxClientCnxns=20500</span><br></pre></td></tr></table></figure>
<p>参数解释：</p>
<ul>
<li><p><strong>dataDir</strong>指定了在第一步中建立的目录，作为zookeeper操作的数据目录。</p>
</li>
<li><p><strong>clientPort</strong>指定了zookeeper客户端连接的端口。该端口可以进行配置更改。配置为11001。</p>
</li>
<li><p><strong>server.id</strong>=host：port1：port2（如server.1=e3base04:11002:11003）中server后的数字id表示该主机是第几号服务器；host是这个服务器的 ip 地址或主机名；port1表示zookeeper服务器通信端口；port2表示选举端口。</p>
</li>
<li><p><strong>maxClientCnxns</strong> 连接zookeeper服务的最大客户端数量，推荐20500。</p>
</li>
</ul>
<p>7、将程序拷贝到其他2台主机：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scp -r zookeeper-3.4.5-cdh5.14.0-e3base3.0.0 e3base02:/e3base/cdh5140/</span><br><span class="line">scp -r zookeeper-3.4.5-cdh5.14.0-e3base3.0.0 e3base03:/e3base/cdh5140/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 分别在2台主机上执行创建软连接</span></span><br><span class="line">ln -s /e3base/cdh5140/zookeeper-3.4.5-cdh5.14.0-e3base3.0.0/ /e3base/zookeeper</span><br></pre></td></tr></table></figure>
<p>8、在zoo.cfg 配置的dataDir目录，部署zookeeper服务的主机目录/e3base/e3-info/zookeeper/data下创建myid文件，文件中写入该主机在zoo.cfg配置信息server.id=host：port1：port2项中对应的数字id。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在e3base03上执行： echo 1 &gt; $E3_INFO_HOME/zookeeper/data/myid </span><br><span class="line"></span><br><span class="line">在e3base04上执行： echo 2 &gt; $E3_INFO_HOME/zookeeper/data/myid </span><br><span class="line"></span><br><span class="line">在e3base05上执行： echo 3 &gt; $E3_INFO_HOME/zookeeper/data/myid </span><br></pre></td></tr></table></figure>
<p>9、<strong>zookeeper启动</strong></p>
<p>登陆zookeeper集群中每台主机启动zookeeper，命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>
<p>通过jps查看各主机上进程是否均已启动。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>主机</th>
<th>进程名</th>
</tr>
</thead>
<tbody>
<tr>
<td>在启动的对应主机上查看</td>
<td>QuorumPeerMain</td>
</tr>
</tbody>
</table>
</div>
<p>启动后可以使用查看zookeeper进程状态,命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure>
<p>正常的集群状态有两种mode：leader、follower</p>
<p>可使用<strong>客户端命令</strong>进行测试，是否zookeeper启动正常，命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkCli.sh -server e3base01:11001,e3base02:11001,e3base03:11001（-server后加参数为zookeeper集群服务的地址和端口）</span><br></pre></td></tr></table></figure>
<p>10、zookeep停止</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh stop</span><br></pre></td></tr></table></figure>
<h3 id="HDFS部署"><a href="#HDFS部署" class="headerlink" title="HDFS部署"></a>HDFS部署</h3><p>1、将安装程序hadoop-2.6.0-cdh5.14.0-e3base3.0.0.tar.gz在/e3base/cdh5140目录下解压</p>
<p>2、设置软连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /e3base/cdh5140/hadoop-2.6.0-cdh5.14.0-e3base3.0.0 /e3base/hadoop</span><br></pre></td></tr></table></figure>
<p>3、配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export IN_HOME=/e3base/</span><br><span class="line">export HADOOP_HOME=$IN_HOME/hadoop</span><br><span class="line">export PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH</span><br><span class="line">使其生效：</span><br><span class="line">source .bash_profile</span><br></pre></td></tr></table></figure>
<p>4、hadoop-env.sh文件配置</p>
<p>特别注意配置文件中的以下参数需要根据实际情况进行修改：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8</span><br><span class="line">export HADOOP_HOME=/e3base/hadoop</span><br><span class="line">export E3_INFO_HOME=/e3base/e3-info</span><br><span class="line">export HADOOP_LOG_DIR=$E3_INFO_HOME/hadoop/logs</span><br><span class="line">export HADOOP_PID_DIR=$E3_INFO_HOME/hadoop/pids</span><br></pre></td></tr></table></figure>
<p>参数解释：</p>
<ul>
<li><strong>JAVA_HOME</strong>配置上安装jdk的目录。</li>
<li><strong>HADOOP_HOME</strong> 配置hadoop应用目录。</li>
<li><strong>HADOOP_LOG_DIR</strong>指定的是Hadoop的日志路径，默认的设置是$HADOOP_HOME/logs，一般需要将其配置到一个磁盘空间比较大的目录下，设置成$E3_INFO_HOME/hadoop/logs。</li>
<li><strong>HADOOP_PID_DIR</strong>指定的是hadoop进程id的存放路径，默认在/tmp下，不修改可能导致无法正常启停，设置成$E3_INFO_HOME/hadoop/pids。</li>
</ul>
<p>注：配置文件中HADOOP_HEAPSIZE、HADOOP_NAMENODE_OPTS、HADOOP_DATANODE_OPTS参数中的JVM堆内存大小，如在测试环境，请注意修改这些参数中的-Xms -Xms -Xmn值符合当前主机环境，如堆内存值配置过大超过系统可用内存，会导致服务启动失败。</p>
<p>5、core-site.xml文件配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​      <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://drmcluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​      <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​      <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base01:11001,e3base02:11001,e3base03:11001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>                                                                                                                                                                </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/e3base/e3-info/hadoop/tmp/hadoop-$&#123;user.name&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>参数解释：</p>
<ul>
<li><p>fs.default.name指定了HDFS的文件系统名称，value格式hdfs://xxxxxx/ 。</p>
</li>
<li><p>ha.zookeeper.quorum指定了用于hadoop namenode失效切换的zookeeper集群信息，填写格式ip:port，多个主机之间以逗号分隔。配置值与zookeeper安装部署保持一致。</p>
</li>
<li><p>hadoop.tmp.dir指定了hadoop临时文件存放目录，配置为/e3base/e3-info/hadoop/tmp/hadoop-${user.name}。</p>
</li>
</ul>
<p>6、hdfs-site.xml文件配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">value</span>&gt;</span>drmcluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>                                                                     </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.nn1.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base01<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.nn2.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base02<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>                                                                  </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>     <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://e3base01:12007;e3base02:12007;e3base03:12007/drmcluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/e3base/e3-info/hadoop/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///e3base/e3-info/hadoop/nn<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>                                                                     </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">​    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/chunk1/hdfs<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>dfs.nameservices指定了集群服务名称，配置为drmcluster。</p>
</li>
<li><p>dfs.namenode.nn1.hostname,dfs.namenode.nn2.hostname分别指定配置namenode服务的主机名，根据实际情况修改。</p>
</li>
<li><p>dfs.ha.namenodes.drmcluster指定了第一个配置项drmcluster集群服务中用于namenode HA的节点名称，配置为nn1、nn2。</p>
</li>
<li><p>dfs.journalnode.edits.dir指定了journal node集群中各主机存储数据的本地磁盘路径，配置成/e3base/e3-info/hadoop/jn。</p>
</li>
<li><p>dfs.namenode.name.dir 配置成file:///e3base/e3-info/hadoop/nn</p>
</li>
<li><p>dfs.namenode.shared.edits.dir和dfs.namenode.name.dir指定了namenode元数据的存储目录，dfs.namenode.shared.edits.dir目录指定了QJM方式实现的元数据存储的路径（qjournal://e3base03:12007;e3base04:12007;e3base05:12007/drmcluster，e3base0*指定了journalnode集群，12007 JournalNode服务通信端口，drmcluster是dfs.nameservices指定了集群服务名称）。</p>
</li>
<li><p>dfs.datanode.data.dir指定了数据节点存放数据的目录，不做raid。（一般设置为挂载多块硬盘的路径），若值设置为/data1/hdfs,/data2/hdfs,/data3/hdfs，则需要在根目录下创建对应的目录，每个/data*目录需挂载到一块数据盘上。</p>
</li>
</ul>
<p>7、slaves文件配置</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/***********************slaves文件内容***********************/</span><br><span class="line"></span><br><span class="line">e3base03</span><br><span class="line"></span><br><span class="line">e3base04</span><br><span class="line"></span><br><span class="line">e3base05</span><br><span class="line"></span><br><span class="line">/************************************************************/</span><br></pre></td></tr></table></figure>
<p>slaves文件中配置了hadoop集群所包含的所有datanode节点，每行对应一个主机名。HDFS和YARN公用。</p>
<p>8、机架感知配置</p>
<p>在/e3base/cdh5140/hadoop/etc/hadoop目录下，修改topology.data文件。根据datanode节点修改相应的IP和主机名，以及机架名（rack）。如果datanode都在同一机架，机架名可相同。</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192.168.248.133 e3base01 /rack1</span><br><span class="line"></span><br><span class="line">192.168.248.134 e3base02 /rack2</span><br><span class="line"></span><br><span class="line">192.168.248.133 e3base03 /rack3</span><br></pre></td></tr></table></figure>
<p>9、将程序拷贝到其他2台主机：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop-2.6.0-cdh5.14.0-e3base3.0.0 e3base02:/e3base/cdh5140</span><br><span class="line">scp -r hadoop-2.6.0-cdh5.14.0-e3base3.0.0 e3base03:/e3base/cdh5140</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 分别在2台主机上执行创建软连接</span></span><br><span class="line">ln -s /e3base/cdh5140/hadoop-2.6.0-cdh5.14.0-e3base3.0.0/ /e3base/hadoop</span><br></pre></td></tr></table></figure>
<p>10、创建对应的路径（只要重启虚拟机，这个路径就会消失，所以<strong>每次重新创建</strong>）（root下）！！！</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/run/hadoop-hdfs/ </span><br><span class="line"></span><br><span class="line">chown -R e3base:e3base  /var/run/hadoop-hdfs/</span><br><span class="line"></span><br><span class="line">chmod -R 755 /var/run/hadoop-hdfs/</span><br></pre></td></tr></table></figure>
<p><strong>11、初始化HDFS</strong></p>
<p>（1）初始化zkfc</p>
<p>在ZK中创建znode来存储automatic Failover的数据，任选一个NN执行完成即可。在一个namenode上进入$HADOOP_HOME/bin执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/bin/hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>
<p>（2）先启动journal node进程。</p>
<p>在每一个journalnode上进入$HADOOP_HOME执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure>
<p>执行完成后，通过jps查看JournalNode进程是否启动正常。</p>
<p>（3）初始化主namenode节点</p>
<p>在需要做主namenode节点主机上进入$HADOOP_HOME/bin执行如下命令实现初始化HDFS目录、文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p>（4）初始化备namenode节点</p>
<p>启动主namenode节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<p>在另外备namenode节点拷贝主namenode节点的元数据，保证两个节点数据一致：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/bin/hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure>
<p><strong>12、启动HDFS</strong></p>
<p>（1）启动hdfs</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>（2）单节点启动namenode进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<p>（3）单节点启动zkfc进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/hadoop-daemon.sh start zkfc</span><br></pre></td></tr></table></figure>
<p>（4）单节点启动datanode进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>
<p>（5）单节点启动journalnode进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure>
<p>（6）启动所有datanode进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/e3base/hadoop/sbin/hadoop-daemons.sh start datanode</span><br></pre></td></tr></table></figure>
<p>ps：如配置了hadoop环境变量，无需进入/e3base/hadoop/sbin/执行</p>
<p><strong>13、HDFS停止</strong></p>
<p>（1）停止hdfs</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;e3base&#x2F;hadoop&#x2F;sbin&#x2F;stop-dfs.sh</span><br></pre></td></tr></table></figure>
<p>（2）单节点停止namenode进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;e3base&#x2F;hadoop&#x2F;sbin&#x2F;hadoop-daemon.sh stop namenode</span><br></pre></td></tr></table></figure>
<p>（3）单节点停止zkfc进程（两个namenode单独停止）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;e3base&#x2F;hadoop&#x2F;sbin&#x2F;hadoop-daemon.sh stop zkfc</span><br></pre></td></tr></table></figure>
<p>（4）单节点停止datanode进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;e3base&#x2F;hadoop&#x2F;sbin&#x2F;hadoop-daemon.sh stop datanode</span><br></pre></td></tr></table></figure>
<p>（5）单节点启动journalnode进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;e3base&#x2F;hadoop&#x2F;sbin&#x2F;hadoop-daemon.sh stop journalnode</span><br></pre></td></tr></table></figure>
<p>（6）停止所有datanode进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;e3base&#x2F;cdh5140&#x2F;hadoop&#x2F;sbin&#x2F;hadoop-daemons.sh stop datanode</span><br></pre></td></tr></table></figure>
<p>ps：如配置了hadoop环境变量，无需进入/e3base/hadoop/sbin/执行</p>
<p><strong>13、HDFS进程查看</strong></p>
<p>jps</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>主机</th>
<th>进程名</th>
</tr>
</thead>
<tbody>
<tr>
<td>$HADOOP_HOME /etc/hadoop下hdfs.xml文件中dfs.namenode.rpc-address.mycluster..*对应的主机</td>
<td>NameNode</td>
</tr>
<tr>
<td>$HADOOP_HOME /etc/hadoop下hdfs.xml文件中dfs.namenode.rpc-address.mycluster..*对应的主机（同NN）</td>
<td>DFSZKFailoverController（zkfc）</td>
</tr>
<tr>
<td>$HADOOP_HOME /etc/hadoop下hdfs.xml文件中dfs.namenode.shared.edits.dir配置项包含的主机</td>
<td>JournalNode</td>
</tr>
<tr>
<td>$HADOOP_HOME /etc/hadoop下slaves文件中包含的主机</td>
<td>DataNode</td>
</tr>
</tbody>
</table>
</div>
<p><strong>13、HDFS状态查看</strong></p>
<p>（1） namenode状态查看</p>
<p>执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs haadmin -getServiceState serviceid</span><br></pre></td></tr></table></figure>
<p>如</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs haadmin -getServiceState nn1</span><br><span class="line"></span><br><span class="line">hdfs haadmin -getServiceState nn2</span><br></pre></td></tr></table></figure>
<p>注：</p>
<p>两种状态：active、standby。serviceid为该主机在$HADOOP_HOME /etc/hadoop下hdfs.xml文件中dfs.namenode.rpc-address.mycluster.*对应的值。</p>
<p>（2） namenode状态手动切换</p>
<p>nn1为active，手动切换成nn2为active，执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop/bin/hdfs haadmin -DFSHAadmin -failover nn1 nn2</span><br></pre></td></tr></table></figure>
<p>（3） namenode离开安全模式</p>
<p>hdfs 是否进入安全模式检查：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode get</span><br></pre></td></tr></table></figure>
<p>离开安全模式，执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop/bin/hdfs dfsadmin -safemode leave</span><br></pre></td></tr></table></figure>
<p>（4） HDFS 健康状态检查</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -report</span><br></pre></td></tr></table></figure>
<p>（5） HDFS数据块完整性检查</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs fsck / </span><br></pre></td></tr></table></figure>
<p><strong>14、HDFS命令使用</strong></p>
<p>（1）文件列表的命令为: </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls</span><br><span class="line"></span><br><span class="line">hdfs dfs -ls路径</span><br></pre></td></tr></table></figure>
<p>不指名路径，默认用户工作目录，为hdfs下的/user/$USER目录（$USER为当前用户）</p>
<p>（2）增加文件目录：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir文件目录路径</span><br></pre></td></tr></table></figure>
<p>（3）用put将文件从本地文件复制到HDFS中去：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put &lt;localsrc&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure>
<p>（4）从HDFS中取回文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -get &lt;localsrc&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure>
<p>（5）删除文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm example.txt</span><br></pre></td></tr></table></figure>
<p><strong>15、HDFS监控页面使用</strong></p>
<p>查看namenode:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;namenodeIP or hostname:port]</span><br><span class="line">(http:&#x2F;&#x2F;masterIP or hostname:port&#x2F;master-status)</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;192.168.229.132:12003&#x2F;</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>namenodeIP</strong> or <strong>hostname</strong>为状态为active的namenode对应IP或hostname</p>
</li>
<li><p><strong>port</strong>为dfs.namenode.http-address.drmcluster.nn1  或 dfs.namenode.http-address.drmcluster.nn2  对应的端口，目前为（12003）</p>
</li>
</ul>
<p>查看 datanode:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;datanodeIP or hostname:port]</span><br><span class="line">(http:&#x2F;&#x2F;regionserverIP or hostname:port &#x2F;rs-status)</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;192.168.229.132:12004&#x2F;</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>datanodeIP</strong> or <strong>hostname</strong>为datanode对应IP或hostname</p>
</li>
<li><p><strong>port</strong>为dfs.datanode.http.address 对应的端口，目前为（12004）。</p>
</li>
</ul>
<p>效果如图：</p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220715193833455.png" class title="image-20220715193833455">
<h3 id="yarn部署"><a href="#yarn部署" class="headerlink" title="yarn部署"></a>yarn部署</h3><p>1、环境变量配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export IN_HOME=/e3base/cdh5140</span><br><span class="line">export HADOOP_HOME=$IN_HOME/hadoop</span><br><span class="line">export PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">source .bash_profile</span><br></pre></td></tr></table></figure>
<p>2、yarn-env.sh文件配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/e3base/jdk</span><br><span class="line">export HADOOP_HOME=/e3base/cdh5140/hadoop</span><br><span class="line">export E3_INFO_HOME=/e3base/e3-info</span><br><span class="line">export YARN_PID_DIR=$E3_INFO_HOME/hadoop/pids</span><br><span class="line">export YARN_LOG_DIR=$E3_INFO_HOME/hadoop/logs</span><br><span class="line">128m 128m</span><br></pre></td></tr></table></figure>
<ul>
<li><p>JAVA_HOME配置上安装jdk的目录,JDK安装路径，默认情况下执行读取linux环境变量${JAVA_HOME}。。</p>
</li>
<li><p>YARN_LOG_DIR指定的是yarn的日志路径。</p>
</li>
<li><p>YARN_PID_DIR 指定的是YARN的进程的pid存放路径。</p>
</li>
</ul>
<p><em>ps：配置文件中YARN_RESOURCEMANAGER_OPTS、YARN_NODEMANAGER_OPTS参数中的JVM堆内存大小，如在测试环境，请注意修改这些参数中的-Xms -Xms -Xmn值符合当前主机环境，如堆内存值配置过大超过系统可用内存，会导致服务启动失败</em></p>
<p>3、yarn-site.xml文件配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base01:11001,e3base02:11001,e3base03:11001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>/chunk1/yarn/local<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>/chunk1/yarn/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.admin.acl<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span>     </span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop-yarn/aggrelogs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>4、fair-scheduler.xml文件配置</p>
<p>集群总容量/内核数量</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;root&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">minResources</span>&gt;</span>1024 mb, 1 vcores<span class="tag">&lt;/<span class="name">minResources</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>40960 mb, 40 vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;default&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">minResources</span>&gt;</span>1024 mb, 1 vcores<span class="tag">&lt;/<span class="name">minResources</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>40960 mb, 40 vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>5、主机间同步</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp yarn-env.sh yarn-site.xml fair-scheduler.xmle3base02:&#x2F;e3base&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;</span><br><span class="line">scp yarn-env.sh yarn-site.xml fair-scheduler.xmle3base03:&#x2F;e3base&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;</span><br></pre></td></tr></table></figure>
<p>6、在mapred-env.sh中增加配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/e3base/hadoop</span><br><span class="line">export E3_INFO_HOME=/e3base/e3-info</span><br><span class="line">export HADOOP_MAPRED_LOG_DIR=$E3_INFO_HOME/hadoop/logs</span><br></pre></td></tr></table></figure>
<p>7、mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>e3base02<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;mapreduce.jobhistory.hostname&#125;:13021<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;mapreduce.jobhistory.hostname&#125;:13022<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>/mr-history/idone<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>/mr-history/done<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>Mapreduce.jobhistory.hostname 填写jobhistory服务主机名</p>
</li>
<li><p>mapreduce.jobhistory.address：MapReduce JobHistory Server地址，地址形式为 主机地址：端口。（注：如部署Jobhistory服务主机处于内外网环境，需配置主机地址为0.0.0.0）在YARN中执行MR代码时，作业向该服务汇报作业的执行历史，从而记录作业的执行信息，供查询用。</p>
</li>
<li><p>mapreduce.jobhistory.webapp.address：MapReduce JobHistory Server Web UI地址。通过web页面查看MR执行状态的地址。配置方式同上。</p>
</li>
<li><p>mapreduce.jobhistory.intermediate-done-dir：MapReduce作业产生的日志存放位置</p>
</li>
<li><p>mapreduce.jobhistory.done-dir：MR JobHistory Server管理的日志的存放位置</p>
</li>
</ul>
<p>8、<strong>yarn启动</strong></p>
<p>（1） 与hdfs同时启动集群</p>
<p>在hadoop active namenode主机上执行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh  </span><br></pre></td></tr></table></figure>
<p>启动hdfs和yarn，若配置了zookeeper，同时启动zkfc</p>
<p>（2）在主管理节点上运行下面指令，仅启动YARN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>（3）在resourcemanager节点启动jobhistoryserver进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh start historyserver </span><br></pre></td></tr></table></figure>
<p>（4） 在YARN中的两个管理节点分别启动resourcemanager进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<p>（5） 在YARN集群中的每个计算节点启动nodemanager进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure>
<p>（6） 启动YARN所有nodemanager节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemons.sh start nodemanager</span><br></pre></td></tr></table></figure>
<p><em>注：YARN的HA启动在主resourcemanager节点执行<code>start-yarn.sh</code>后，在备节点执行<code>yarn-daemon.sh start resourcemanager</code></em></p>
<p>9、<strong>yarn停止</strong></p>
<p>（1） 与hdfs同时停止hdfs集群</p>
<p>在hadoop active namenode主机e3base01上执行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-all.sh  </span><br></pre></td></tr></table></figure>
<p>（2） 在主管理节点上运行下面指令，仅停止YARN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-yarn.sh</span><br></pre></td></tr></table></figure>
<p>（3） 在namenode的备节点停止jobhistoryserver进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh stop historyserver </span><br></pre></td></tr></table></figure>
<p>（4） 在YARN中的两个管理节点分别停止resourcemanager进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh stop resourcemanager</span><br></pre></td></tr></table></figure>
<p>（5） 在YARN集群中的每个计算节点停止nodemanager进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh stop nodemanager</span><br></pre></td></tr></table></figure>
<p>（6） 停止YARN所有nodemanager节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemons.sh stop nodemanager</span><br></pre></td></tr></table></figure>
<p>10、yarn进程查看</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">主机</th>
<th style="text-align:center">进程名</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">在$HADOOP_HOME/etc/hadoop/slaver中对应主机上查看</td>
<td style="text-align:center">NodeManager</td>
</tr>
<tr>
<td style="text-align:center">在主管理节点</td>
<td style="text-align:center">ResourceManager</td>
</tr>
</tbody>
</table>
</div>
<p>11、yarn指令执行</p>
<p>在YARN集群中的任意一个节点中执行下列指令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yarn rmadmin -getServiceState rm1</span><br><span class="line"></span><br><span class="line">yarn rmadmin -getServiceState rm2</span><br></pre></td></tr></table></figure>
<p>返回的结果是active或者stanby。只有且必须是两种状态之一，否则YARN工作不正常。</p>
<p>查看YARN集群的节点状态。执行下列指令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn node -list -all</span><br></pre></td></tr></table></figure>
<p>若返回的节点数量和集群中的$HADOOP_HOME/etc/hadoop/slave的主机一样且显示RUNNING状态，则YARN的计算节点工作正常</p>
<p>查看所有任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn application -list</span><br></pre></td></tr></table></figure>
<p>12、监控页面<a target="_blank" rel="noopener" href="http://${yarn.resourcemanager.rm1}:8088">http://${yarn.resourcemanager.rm1}: 1</a>3006</p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721123948884.png" class title="image-20220721123948884">
<p>13、运行wordcount示例：</p>
<p>（1）创建几个HDFS目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /zwl/wordcount （输入数据源目录）</span><br><span class="line"></span><br><span class="line">hadoop fs -mkdir -p /output/     （输出结果目录）</span><br></pre></td></tr></table></figure>
<p>2.创建源数据文件 vi inputword </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hello abountyun</span><br><span class="line"></span><br><span class="line">hello master</span><br><span class="line"></span><br><span class="line">hello slave</span><br><span class="line"></span><br><span class="line">hello slave</span><br><span class="line"></span><br><span class="line">abountyun first</span><br></pre></td></tr></table></figure>
<p>3.将本地文件上传到HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put inputword /zwl/wordcount</span><br></pre></td></tr></table></figure>
<p>查看文件内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -text /zwl/wordcount/inputword</span><br></pre></td></tr></table></figure>
<p>（4） 执行mapreduce程序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /e3base/hadoop/share/hadoop/mapreduce</span><br><span class="line"></span><br><span class="line">hadoop jar ./hadoop-mapreduce-examples-2.6.0-cdh5.14.0.jar wordcount /zwl/wordcount  /output/wordcount  </span><br></pre></td></tr></table></figure>
<p>等待执行完毕</p>
<p>（5）查看输出结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -text /output/wordcout/part-r-00000</span><br></pre></td></tr></table></figure>
<p>运行过程如下：</p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721125506134.png" class title="image-20220721125506134">
<p>输出内容如下：</p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721125820845.png" class title="image-20220721125820845">
<p>访问<a target="_blank" rel="noopener" href="http://ResourceManager主机ip:13006/">http://ResourceManager主机ip:13006/</a> 可查看任务执行情况</p>
<img src="/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/image-20220721125417043.png" class title="image-20220721125417043">

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>Zhao.W.L
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://polaris6g.github.io/2022/07/15/Hadoop%E5%AE%9E%E6%93%8D%E6%A6%82%E8%BF%B0/" title="Hadoop实操概述">https://polaris6g.github.io/2022/07/15/Hadoop实操概述/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%80%9D%E7%89%B9%E5%A5%87%E5%9F%B9%E8%AE%AD%E8%AF%BE%E7%A8%8B/" rel="tag"># 思特奇培训课程</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/07/12/hadoop%E6%97%B6%E4%BB%A3%E8%83%8C%E6%99%AF/" rel="prev" title="hadoop时代背景">
      <i class="fa fa-chevron-left"></i> hadoop时代背景
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/07/17/hdfs%E5%AE%9E%E6%93%8D/" rel="next" title="hdfs实操">
      hdfs实操 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">Hadoop介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS"><span class="nav-number">1.0.1.</span> <span class="nav-text">HDFS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN"><span class="nav-number">1.0.2.</span> <span class="nav-text">YARN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce"><span class="nav-number">1.0.3.</span> <span class="nav-text">MapReduce</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Zookeeper"><span class="nav-number">1.0.4.</span> <span class="nav-text">Zookeeper</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#QJM"><span class="nav-number">1.0.5.</span> <span class="nav-text">QJM</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop%E9%83%A8%E7%BD%B2"><span class="nav-number">2.</span> <span class="nav-text">Hadoop部署</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%AE%BE%E7%BD%AE"><span class="nav-number">2.0.1.</span> <span class="nav-text">集群部署设置</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85%E5%AE%9E%E6%93%8D%E7%9B%AE%E6%A0%87"><span class="nav-number">3.</span> <span class="nav-text">大数据基础平台安装实操目标</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mysql%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8"><span class="nav-number">3.0.1.</span> <span class="nav-text">mysql安装使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%B9%B3%E9%9D%A2%E9%83%A8%E7%BD%B2%E5%87%86%E5%A4%87"><span class="nav-number">3.0.2.</span> <span class="nav-text">大数据基础平面部署准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#zookeeper%E9%83%A8%E7%BD%B2"><span class="nav-number">3.0.3.</span> <span class="nav-text">zookeeper部署</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E9%83%A8%E7%BD%B2"><span class="nav-number">3.0.4.</span> <span class="nav-text">HDFS部署</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#yarn%E9%83%A8%E7%BD%B2"><span class="nav-number">3.0.5.</span> <span class="nav-text">yarn部署</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhao.W.L"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhao.W.L</p>
  <div class="site-description" itemprop="description">This is a blog in order to record my learning and growth.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-02 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhao.W.L</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '4xaQ3oibwykcx9Txo8mrwUu6-gzGzoHsz',
      appKey     : 'QMeC2pntBViR7uy1yqBAtAuH',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
